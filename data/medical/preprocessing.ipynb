{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical dataset\n",
    "\n",
    "NOTE: UK Biobank is not a public dataset - access can be requested https://www.ukbiobank.ac.uk/\n",
    "\n",
    "Prerequisites:\n",
    "- enc_ukb file from UK Biobank with the required variables (listed in `inputs/covariates.txt`) and the software programs for working with this type of file\n",
    "- UK Biobank Primary Care Linked Data for the gp_clinical and gp_scripts tables. See UK Biobank Resource 591 for further details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "PATH_TO_ROOT = '' # TODO replace\n",
    "PATH_TO_UKBB_DATA = '' # TODO replace\n",
    "UKBB_APPLICATION_NUMBER = '' # TODO replace\n",
    "OUTPATH = f'{PATH_TO_ROOT}/data/medical/data/raw'\n",
    "DATAPATH = 'data/ukb{UKBB_APPLICATION_NUMBER}.csv'\n",
    "fields_df = pd.read_csv('inputs/covariates.txt')\n",
    "covariate_fields_df = fields_df[fields_df['Variable']=='covariate']\n",
    "clinical_fields_df = fields_df[fields_df['Variable']=='clinical']\n",
    "diagnosis_fields_df = fields_df[fields_df['Variable']=='diagnosis']\n",
    "tre_df = pd.read_csv('inputs/treatment.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection to db\n",
    "DBPATH = f'{PATH_TO_UKBB_DATA}/data/raw/ehr/ehr.db'\n",
    "conn = sqlite3.connect(DBPATH)\n",
    "conn.text_factory = lambda b: b.decode(errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util to remove outlier values in a column of a pandas dataframe\n",
    "outlier_df = lambda df, col: df[(np.abs(stats.zscore(df[col])) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get diagnosis variables (aggregate from several ICD codes)\n",
    "DVT = ['132198-0.0','131400-0.0']\n",
    "AAA = ['131394-0.0','131382-0.0']\n",
    "Stroke = ['131378-0.0','131374-0.0','131372-0.0','131366-0.0','131058-0.0']\n",
    "CAD = ['131306-0.0','131304-0.0','131302-0.0','131300-0.0','131298-0.0','131296-0.0']\n",
    "\n",
    "outcomes = {'DVT': DVT, 'AAA': AAA, 'Stroke': Stroke, 'CAD': CAD}\n",
    "\n",
    "for outcome in outcomes:\n",
    "    for code in outcomes[outcome]:\n",
    "        df[code] = pd.to_datetime(df[code])\n",
    "    df[outcome] = df[outcomes[outcome]].min(axis=1)\n",
    "\n",
    "df['Any_Outcome'] = df[['DVT','AAA','Stroke','CAD']].min(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get covariates (age, sex)\n",
    "data = df[['eid','130708-0.0','31-0.0','34-0.0','AAA','DVT','Stroke','CAD','Any_Outcome']].rename(columns={'31-0.0':'Sex','34-0.0':'Year of birth'})\n",
    "data = data.dropna(subset=['130708-0.0']).rename(columns={'130708-0.0':'T2D'})\n",
    "patient_list = data['eid'].tolist()\n",
    "data.to_csv('{}/patient_covariates.csv'.format(OUTPATH), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get treatments (from prescriptions table)\n",
    "table='gp_scripts'\n",
    "\n",
    "read2_codes = ', '.join([\"'{}'\".format(x) for x in tre_df[tre_df['Type']=='read_2']['Code']])\n",
    "bnf_codes = ', '.join([\"'{}'\".format(x) for x in tre_df[tre_df['Type']=='bnf_code']['Code']])\n",
    "dmd_codes = ', '.join([\"'{}'\".format(x) for x in tre_df[tre_df['Type']=='dmd_code']['Code']])\n",
    "\n",
    "command = 'SELECT * FROM {} WHERE (read_2 IN ({}) OR bnf_code IN ({}) OR dmd_code IN ({}))'.format(table, read2_codes, bnf_codes, dmd_codes)\n",
    "\n",
    "data = pd.read_sql_query(command, conn)\n",
    "\n",
    "# map the codes to the drug label\n",
    "code_map = dict(zip(tre_df['Code'],tre_df['Label'])) # use read 2 codes because drug name is blank\n",
    "t1 = data[data['read_2']!='']\n",
    "t1['treatment'] = t1['read_2'].map(code_map)\n",
    "t2 = data[data['read_2']=='']\n",
    "code_map = dict(zip(tre_df['Description'],tre_df['Label'])) # use description because other drugs had same codes\n",
    "t2['treatment'] = t2['drug_name'].map(code_map)\n",
    "\n",
    "data = pd.concat([t1,t2])\n",
    "\n",
    "treatments = {'atorvastatin':'atorvastatin',\n",
    "              'lipitor':'atorvastatin', \n",
    "              'fluvastatin':'fluvastatin', \n",
    "              'lescol':'fluvastatin', \n",
    "              'lovastatin':'lovastatin',\n",
    "              'altoprev':'lovastatin', \n",
    "              'pitavastatin':'pitavastatin', \n",
    "              'livalo':'pitavastatin', \n",
    "              'zypitamag':'pitavastatin', \n",
    "              'pravastatin':'pravastatin',\n",
    "              'pravachol':'pravastatin', \n",
    "              'rosuvastatin':'rosuvastatin',\n",
    "              'crestor':'rosuvastatin',\n",
    "              'ezallor':'rosuvastatin', \n",
    "              'simvastatin':'simvastatin', \n",
    "              'zocor':'simvastatin'}\n",
    "\n",
    "t1 = data[~data['treatment'].isna()]\n",
    "t2 = data[data['treatment'].isna()]\n",
    "\n",
    "t2['treatment'] = t2['drug_name'].apply(lambda x: next((v for k, v in treatments.items() if k in x.lower()), None))\n",
    "print(\"{} rows cannot be identified\".format(len(t2[t2['treatment'].isna()]))) \n",
    "t2 = t2[~t2['treatment'].isna()]\n",
    "data = pd.concat([t1,t2])\n",
    "\n",
    "# data cleaning\n",
    "data = data[['eid','issue_date','treatment']]\n",
    "data = data[data['eid'].astype('int').isin(patient_list)]\n",
    "data = data.dropna()\n",
    "data = data[~(data['issue_date']=='')]\n",
    "data['issue_date'] = pd.to_datetime(data['issue_date'], format='%d/%m/%Y')\n",
    "data.rename(columns={'issue_date':'event_dt'}, inplace=True)\n",
    "\n",
    "data.to_csv('{}/treatment.csv'.format(OUTPATH), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get biomarkers\n",
    "table='gp_clinical'\n",
    "read2_codes = ', '.join([\"'{}'\".format(x) for x in clinical_fields_df[clinical_fields_df['Type']=='read2']['Code']])\n",
    "read3_codes = ', '.join([\"'{}'\".format(x) for x in clinical_fields_df[clinical_fields_df['Type']=='read3']['Code']])\n",
    "\n",
    "if len(read2_codes)>0 and len(read3_codes)>0:\n",
    "    command = 'SELECT * FROM {} WHERE (read_2 IN ({}) OR read_3 IN ({}))'.format(table, read2_codes, read3_codes)\n",
    "elif len(read2_codes)>0:\n",
    "    command = 'SELECT * FROM {} WHERE read_2 IN ({})'.format(table, read2_codes)\n",
    "elif len(read3_codes)>0:\n",
    "    command = 'SELECT * FROM {} WHERE read_3 IN ({})'.format(table, read3_codes)\n",
    "    \n",
    "data = pd.read_sql_query(command, conn)\n",
    "\n",
    "# data cleaning\n",
    "code_map = dict(zip(clinical_fields_df['Code'],clinical_fields_df['Description']))\n",
    "data['read_3'] = data['read_3'].map(code_map)\n",
    "data['read_2'] = data['read_2'].map(code_map)\n",
    "data['read_3'] = data['read_3'].fillna(data['read_2'])\n",
    "data['value'] = pd.to_numeric(data['value1'], errors='coerce')\n",
    "data = data[['eid','event_dt','read_3','value']]\n",
    "data = data[data['eid'].astype('int').isin(patient_list)]\n",
    "data = data.dropna()\n",
    "data = data[~(data['event_dt']=='')]\n",
    "data['event_dt'] = pd.to_datetime(data['event_dt'], format='%d/%m/%Y')\n",
    "data.rename(columns={'read_3':'variable'}, inplace=True)\n",
    "\n",
    "# remove outliers\n",
    "data = data[data['value']>0] \n",
    "final_data = pd.DataFrame()\n",
    "\n",
    "for variable in data['variable'].unique():\n",
    "    final_data = pd.concat([final_data,outlier_df(data[data['variable']==variable], 'value')])\n",
    "\n",
    "final_data.to_csv('{}/covariate_clinical.csv'.format(OUTPATH), index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assemble the different data sources into a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('{}/patient_covariates.csv'.format(OUTPATH))\n",
    "\n",
    "# convert all datetime columns to years\n",
    "for col in ['T2D','AAA','DVT','Stroke','CAD']:\n",
    "    df[col] = pd.to_datetime(df[col]).dt.year\n",
    "\n",
    "df['Age_at_T2D_diagnosis'] = df['T2D'] - df['Year of birth']\n",
    "# remove patients diagnosed before birth - indicates an error in the record\n",
    "df = df[df['Age_at_T2D_diagnosis']>=0]\n",
    "\n",
    "INDEX_YEAR = 2000 # only consider patients with a diagnosis before the index year\n",
    "FINAL_YEAR = 2020 # the final year to consider patients for\n",
    "num_samples_per_task = 12 # fix across patients\n",
    "\n",
    "data = df[df['T2D']<INDEX_YEAR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "patient_list = data['eid'].tolist()\n",
    "\n",
    "df_clin = pd.read_csv('{}/covariate_clinical.csv'.format(OUTPATH))\n",
    "df_clin['type'] = 'biomarker'\n",
    "df_tre = pd.read_csv('{}/treatment.csv'.format(OUTPATH))\n",
    "df_tre.rename(columns={'treatment':'variable'}, inplace=True)\n",
    "df_tre['value'] = 1\n",
    "df_tre['type'] = 'intervention'\n",
    "intervention_variables = df_tre['variable'].unique().tolist()\n",
    "df_clin = pd.concat([df_clin, df_tre])\n",
    "\n",
    "df_clin['event_dt'] = pd.to_datetime(df_clin['event_dt']).dt.year\n",
    "df_clin = df_clin[(df_clin['event_dt']>=INDEX_YEAR)&(df_clin['event_dt']<=FINAL_YEAR)]\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "num_Y = {}\n",
    "\n",
    "# only consider patients with at least 1 patient record\n",
    "for patient in tqdm(patient_list):\n",
    "\n",
    "    tmp = df_clin[df_clin['eid']==patient]\n",
    "\n",
    "    if 'Cholesterol' in tmp['variable'].tolist():\n",
    "\n",
    "        tmp = tmp.groupby(['event_dt','variable']).mean().reset_index().pivot(index='event_dt',columns='variable',values='value').reset_index()\n",
    "\n",
    "        # only backfill previous years (e.g., patient may have died before FINAL_YEAR)\n",
    "        tmp = pd.merge(pd.DataFrame({'event_dt':range(INDEX_YEAR,tmp['event_dt'].max()+1)}), tmp, on='event_dt', how='left')\n",
    "\n",
    "        num_Y[patient] = len(tmp[~tmp['Cholesterol'].isna()])\n",
    "        \n",
    "        # fill missing intervention variables with 0 (to indicate that no intervention occurred)\n",
    "        tmp_interv = list(set(tmp.keys()).intersection(set(intervention_variables)))\n",
    "        if len(tmp_interv)>0:\n",
    "            tmp[tmp_interv] = tmp[tmp_interv].fillna(0)\n",
    "\n",
    "        # impute the other variables using the most recent value\n",
    "        tmp = tmp.ffill().bfill()\n",
    "        tmp.insert(0, 'eid', patient)\n",
    "        final_df = pd.concat([final_df, tmp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "final_df[intervention_variables] = final_df[intervention_variables].fillna(0)\n",
    "df = final_df.dropna()\n",
    "\n",
    "tmp = df.groupby('eid').count()\n",
    "tmp['num_Y'] = tmp.index.map(num_Y)\n",
    "num_Y_per_task = num_samples_per_task\n",
    "patient_list = tmp[(tmp['event_dt']>=num_samples_per_task) & (tmp['num_Y']>=num_samples_per_task)].index.tolist()\n",
    "\n",
    "df = df[df['eid'].isin(patient_list)]\n",
    "\n",
    "label_df = pd.read_csv('{}/patient_covariates.csv'.format(OUTPATH))\n",
    "\n",
    "for col in ['T2D','AAA','DVT','Stroke','CAD','Any_Outcome']:\n",
    "    label_df[col] = pd.to_datetime(label_df[col]).dt.year\n",
    "\n",
    "label_df = label_df[label_df['eid'].isin(patient_list)]\n",
    "df = pd.merge(df, label_df, on='eid', how='left')\n",
    "\n",
    "df['Age'] = df['event_dt'] - df['Year of birth']\n",
    "df['Age at T2D diagnosis'] = df['T2D'] - df['Year of birth']\n",
    "df = df.drop(columns=['T2D','Year of birth'])\n",
    "\n",
    "for col in ['AAA','DVT','Stroke','CAD','Any_Outcome']:\n",
    "    # indicator = 1 if patient has any history with that disease\n",
    "    df[col] = (df[col] <= df['event_dt']).astype(int)\n",
    "\n",
    "df = df[df['event_dt']<=FINAL_YEAR]\n",
    "\n",
    "tmp = df.groupby('eid').count()\n",
    "patient_list = tmp[tmp['event_dt']>=num_samples_per_task].index.tolist()\n",
    "\n",
    "# only keep patients with min number of data samples\n",
    "df = df[(df['eid'].isin(patient_list))]\n",
    "\n",
    "# fix issue where some Creatinine values are given in wrong unit\n",
    "df['Creatinine'] = df['Creatinine'].apply(lambda x : x/1000 if x>1000 else x)\n",
    "\n",
    "df = df[['eid','Cholesterol','BMI','DBP','SBP','atorvastatin', 'simvastatin','rosuvastatin', 'pravastatin', 'fluvastatin','Sex','AAA','DVT','Stroke','CAD','Age','Age at T2D diagnosis']]\n",
    "\n",
    "# combine infrequent statins into one variable\n",
    "df['other_statin'] = (df['rosuvastatin'] + df['pravastatin'] + df['fluvastatin'] >0).astype(int)\n",
    "df = df.drop(columns=['rosuvastatin', 'pravastatin', 'fluvastatin'])\n",
    "\n",
    "# convert the task column to indices\n",
    "task_map = dict(zip(df['eid'].unique(), range(len(df['eid'].unique()))))\n",
    "df['task'] = df['eid'].map(task_map)\n",
    "df = df.drop(columns=['eid'])\n",
    "\n",
    "# rename the feature columns\n",
    "df = df.rename(columns={'Cholesterol':'Y'})\n",
    "df = df.rename(columns={feature:'X_{}'.format(feature) for feature in df.keys() if feature not in ['Y','task']})\n",
    "\n",
    "# same number of samples per patient\n",
    "final_df = pd.DataFrame()\n",
    "for patient in df['task'].unique():\n",
    "    tmp = df[df['task']==patient][0:num_samples_per_task]\n",
    "    final_df = pd.concat([final_df, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analytics\n",
    "final_df.drop(columns='task').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from utils import get_train_val_test_data\n",
    "\n",
    "NUM_DATASETS = 6\n",
    "DATASET_NAME = 'medical'\n",
    "INTERVENTIONS = ['X_atorvastatin', 'X_simvastatin', 'X_other_statin']\n",
    "\n",
    "full_datasets, full_interv_masks = get_train_val_test_data(final_df, NUM_DATASETS, INTERVENTIONS)\n",
    "\n",
    "for dataset in range(NUM_DATASETS):\n",
    "    tmp = full_datasets[dataset]\n",
    "    tmp.to_csv(f'data/processed/{DATASET_NAME}_dataset{dataset}.csv', index=None)\n",
    "    full_interv_masks[dataset].to_csv(f'data/processed/{DATASET_NAME}_dataset{dataset}_mask.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (module anaconda/2020-03-tf1)",
   "language": "python",
   "name": "python3-tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b3ed8a42dbbbe3a6ae6a82eeecbcfe1bd4c2aa94426d0630adee1d4eaaf6f37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
